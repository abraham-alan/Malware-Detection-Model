getwd()
setwd("~/ALY-6020")
library(tidyverse)
library(caret)
library(rpart)
library(randomForest)
library(MASS)

#add memory
memory.limit(size=66000)
malware.train <- fread("MicrosoftMalwareDataTrain.csv")
malware.test <- fread("MicrosoftMalwareTest.csv")

#save as r file to save space
save(malware.train, file = "C:/Users/Home/Documents/ALY-6020/malware.train.rdata")
save(malware.test, file = "C:/Users/Home/Documents/ALY-6020/malware.test.rdata")
#remove and reload 
# rm(list=ls())
#reload as just rdata
load("C:/Users/Home/Documents/ALY-6020/malware.train.rdata")
load("C:/Users/Home/Documents/ALY-6020/malware.test.rdata")


#take just a sample to reduce memory usage
set.seed(111) #allow reproduceablility
train.mw <- malware.train[sample(nrow(malware.train), nrow(malware.train)*0.1),]
save(train.mw, file = "~/ALY-6020/sample.train.malware.rdata")
load("~/ALY-6020/sample.train.malware.rdata")
str(train.mw)


# convert all characters to factors
train.mw <- train.mw %>% mutate_if(is.character, as.factor)
#check if it worked
str(train.mw)
#yes!
#check for NAs
colSums(is.na(train.mw))
#remove columns with more than 10,000 NAs
train.mw1 <-  subset(train.mw, select = colSums(is.na(train.mw))<=10000)
# removed 14 variables
str(train.mw)

# impute for NAs for numeric columns
#subset numeric columns
train.numeric <- train.mw1[, lapply(train.mw1, is.numeric) == TRUE, with = FALSE]
# # mice package for imputing
# add the mean value for each numeric type
train.numeric1 <- data.frame(
  sapply(train.numeric,
    function(x) ifelse(is.na(x),
                       mean(x, na.rm = TRUE),
                       x)))
sum(is.na(train.numeric1))
# worked!
rm(train.mw)

save(train.numeric1, file = "~/ALY-6020/train.numeric1.rdata")
save(train.mw1, file = "~/ALY-6020/train.mw1.rdata")
train.categorical <- dplyr::select(train.mw1, -contains(names(train.numeric)))
sum(is.na(train.categorical))
#0!
#combine dataframes
train.complete <- cbind(train.numeric1, train.categorical)
#delete the columns with too skewed values and eliminate features that account for more 
# than 99% of all eigenvalues
train.complete1 <- dplyr::select(train.complete,-c(AutoSampleOptIn, UacLuaenable))

load("~/ALY-6020/train.complete1.rdata")

colSums(is.na(train.complete1))
#no NAs!!!

#finally ready to build the model
table(train.complete1$HasDetections)
# 0      1 
# 446407 445741 

# build logistic regression model
# only use numeric data columns
# convert target to factor
# scale the values
# divide into test and train
train.numeric.norm <- as.data.frame(scale(train.numeric1[,-39]))
train.numeric.norm$HasDetections <-  as.factor(train.numeric1$HasDetections)
set.seed(111)
sample <- sample(c(TRUE, FALSE), nrow(train.numeric.norm), replace=TRUE, prob=c(0.7,0.3))
sample.train.numeric <- train.numeric.norm[sample,]
numeric.test <- train.numeric.norm[!sample,]
log.model <- glm(HasDetections ~. , family = binomial(link = 'logit'),
                 data = sample.train.numeric)
memory.limit(size = 800000)
log.predict <- predict(log.model, numeric.test[,-39], type = 'response')
#transform probabilities to yes or no with .5 as cut-off
log.predictions <- ifelse(log.predict > 0.5,"1","0")
log.predictions <- as.factor(log.predictions)
#confusion matrix
confusionMatrix(numeric.test$HasDetections,log.predictions)
#plot the matrix
log.matrix <- confusionMatrix(numeric.test$HasDetections,log.predictions)
library(cvms)
#convert to tibble to plot the matrix. substract 1 because "as.numeric" automatically adds 1
log.tibble <- tibble("target" = as.numeric(numeric.test$HasDetections)-1,
                     "predict" = as.numeric(log.predictions)-1)
log.eval <- evaluate(log.tibble,
                  target_col = "target",
                  prediction_cols = "predict",
                  type = "binomial")
plot_confusion_matrix(log.eval)
log.eval.df <- data.frame(log.eval)
log.eval.df
#create ROC plot
library(pROC)
log.roc <- roc(log.tibble$target, log.tibble$predict)
ggroc(log.roc)

# The y-axis displays the sensitivity (the true positive rate) of the model
# and the x-axis displays the specificity (the true negative rate) of the model
# add now the AUC value
log.auc <-round(auc(log.tibble$target, log.tibble$predict),4)
ggroc(log.roc, colour= 'steelblue', size = 2)+
  ggtitle(paste0('ROC Curve for Logistic Regression Model', ' (AUC = ', log.auc, ')'))+
  theme_minimal()






##############################################
#create random forest model
# first reduce features to the main 14 and scale the numeric ones
train.numeric <- train.complete1[, lapply(train.complete1, is.numeric) == TRUE]
train.numeric.norm <- data.frame(scale(train.numeric))

#create the categorical df
train.categorical <- dplyr::select(train.complete1, -contains(names(train.numeric)))
#combine dataframes
train.complete <- cbind(train.numeric.norm, train.categorical)


#too large a dataset. Let's include only these relevant columns:
train.rf1 <- dplyr::select(train.complete,c(EngineVersion,
 AvSigVersion,
 CountryIdentifier,
 OsVer,
 IsProtected,
 Firewall,
 HasTpm,
 SmartScreen,
 Census_SystemVolumeTotalCapacity,
 Platform,
 Census_TotalPhysicalRAM,
 Census_HasOpticalDiskDrive,
 Census_IsTouchEnabled,
 HasDetections))
 
train.rf1$HasDetections <-  as.factor(train.rf1$HasDetections)

 set.seed(111) #allow reproduceablility
 train.rf2 <- train.rf1[sample(nrow(train.rf1), nrow(train.rf1)*0.3),]
# divide training and test 
 set.seed(111)
 sample <- sample(c(TRUE, FALSE), nrow(train.rf2), replace=TRUE, prob=c(0.7,0.3))
rf.train <- train.rf2[sample,] 
rf.test <- train.rf2[!sample,]
#remove y variable from test set
rf.test.x <- rf.test[,-14]
rf_model <- train(HasDetections~.,
                    data = rf.train,
                    method = "rf",
                    trControl= trainControl(),
                    metric = "Accuracy")

#took too long. let's try a different package
library(randomForest)
rf.model <- randomForest(HasDetections ~., rf.train, mtry=5, ntree=500)
# model doesn't work if factor has more than 53 categories
lq <- function(x){length(unique(x))} 
lis <- lapply(train.complete1, lq)
lists <- lis >53
lis1 <-which(lists == TRUE)
names(lis1)
#remove all factor columns with more than 53 levels
rf1 <-dplyr::select(rf.train, -contains(names(lis1)))
#let's try again now
rf.model <- randomForest(HasDetections ~., rf1, mtry=5, ntree=500)
varImpPlot(rf.model)
# worked!
#make predictions on test set
rf.predict <- predict(rf.model, rf.test.x, type = 'response' )
library(caret)
confusionMatrix(rf.test$HasDetections,rf.predict)
#plot the matrix
rf.matrix <- confusionMatrix(rf.test$HasDetections,rf.predict)
library(cvms)
#convert to tibble to plot the matrix. substract 1 because "as.numeric" automatically adds 1
rf.tibble <- tibble("target" = as.numeric(rf.test$HasDetections)-1,
                     "predict" = as.numeric(rf.predict)-1)
rf.eval <- cvms::evaluate(rf.tibble,
                     target_col = "target",
                     prediction_cols = "predict",
                     type = "binomial")

ls()
plot_confusion_matrix(rf.eval)
rf.eval.df <- data.frame(rf.eval)
#save before the next command!!!!
rf.eval.df
#create ROC plot
library(pROC)
rf.roc <- roc(rf.tibble$target, rf.tibble$predict)
ggroc(rf.roc)

# add now the AUC value
rf.auc <-round(auc(rf.tibble$target, rf.tibble$predict),4)
ggroc(rf.roc, colour= 'steelblue', size = 2)+
  ggtitle(paste0('ROC Curve for Random Forest Prediction Model', ' (AUC = ', 0.5753, ')'))+
  theme_minimal()


